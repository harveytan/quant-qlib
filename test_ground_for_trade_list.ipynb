{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from utils import prints\n",
    "import qlib\n",
    "from qlib.data import D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[32032:MainThread](2025-12-28 18:05:48,728) INFO - qlib.Initialization - [config.py:452] - default_conf: client.\n",
      "[32032:MainThread](2025-12-28 18:05:49,503) INFO - qlib.Initialization - [__init__.py:79] - qlib successfully initialized based on client settings.\n",
      "[32032:MainThread](2025-12-28 18:05:49,504) INFO - qlib.Initialization - [__init__.py:81] - data_path={'__DEFAULT_FREQ': WindowsPath('C:/Users/harve/.qlib/qlib_data/us_data')}\n"
     ]
    }
   ],
   "source": [
    "# initialize qlib\n",
    "qlib.init(provider_uri=\"C:/Users/harve/.qlib/qlib_data/us_data\", region=\"us\")\n",
    "\n",
    "# ‚úÖ Load trained model\n",
    "with open(\"trained_model_2.pkl\", \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "model = obj[\"model\"]\n",
    "training_columns = obj[\"columns\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using date range: 2025-11-28 to 2025-12-29\n",
      "Using training columns: ['$open', '$high', '$low', '$close', '$vol_5d', '$rank_vol_5d', '$volume_log']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚úÖ Define date range and instruments\n",
    "START_DATE = (datetime.today() - timedelta(days=30)).strftime(\"%Y-%m-%d\") #START_DATE = \"2025-01-01\"\n",
    "END_DATE = (datetime.today() + timedelta(days=1)).strftime(\"%Y-%m-%d\")    #END_DATE = \"2030-10-18\"\n",
    "prints(f\"Using date range: {START_DATE} to {END_DATE}\", \"trade_list_ensemble_log.txt\")\n",
    "prints(f\"Using training columns: {training_columns}\", \"trade_list_ensemble_log.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_path = r\"C:/Users/harve/.qlib/qlib_data/us_data/instruments/all.txt\"\n",
    "with open(instrument_path, \"r\") as f:\n",
    "    instrumentx = [line.strip().split(\"\\t\")[0] for line in f if line.strip()]\n",
    "# ‚úÖ Load features and realized returns\n",
    "raw_fields = [\"$open\", \"$high\", \"$low\", \"$close\", \"$volume\",\n",
    "            \"$ret_5d\", \"$vol_5d\", \"$rank_vol_5d\", #\"$rank_ret_5d\",\n",
    "            \"$ret_10d\", \"$vol_10d\", \"$rank_ret_10d\", \"$rank_vol_10d\",\n",
    "            \"$ret_20d\", \"$vol_20d\", \"$rank_ret_20d\", \"$rank_vol_20d\", \"$days_since_ipo\"]\n",
    "\n",
    "features = D.features(instruments=instrumentx, fields=raw_fields,\n",
    "                    start_time=START_DATE, end_time=END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"$volume_log\"] = np.log1p(features[\"$volume\"])\n",
    "features.drop(columns=[\"$volume\"], inplace=True)\n",
    "\n",
    "diagnostic_cols = [\"$ret_5d\", \"$days_since_ipo\"]  # add more if needed\n",
    "cols_to_keep = training_columns + [c for c in diagnostic_cols if c in features.columns]\n",
    "\n",
    "features = features[cols_to_keep]\n",
    "\n",
    "# Slice only training columns for prediction\n",
    "X_for_model = features[training_columns]\n",
    "\n",
    "labels = D.features(instruments=instrumentx,\n",
    "                    fields=[\"$ret_5d\", \"$ret_10d\", \"$ret_20d\"],\n",
    "                    start_time=START_DATE, end_time=END_DATE)\n",
    "\n",
    "\n",
    "# ‚úÖ Score features\n",
    "# features = features.dropna(subset=training_columns)\n",
    "features[\"score\"] = model.predict(X_for_model)\n",
    "\n",
    "df_combined = pd.concat([features, labels], axis=1)\n",
    "df_combined = df_combined.dropna(subset=[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 39 entries, ('AAPL', Timestamp('2025-11-28 00:00:00')) to ('WMT', Timestamp('2025-11-28 00:00:00'))\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   $open            39 non-null     float32\n",
      " 1   $high            39 non-null     float32\n",
      " 2   $low             39 non-null     float32\n",
      " 3   $close           39 non-null     float32\n",
      " 4   $vol_5d          39 non-null     float32\n",
      " 5   $rank_vol_5d     39 non-null     float32\n",
      " 6   $volume_log      39 non-null     float32\n",
      " 7   $ret_5d          0 non-null      float32\n",
      " 8   $days_since_ipo  39 non-null     float32\n",
      " 9   score            39 non-null     float64\n",
      " 10  $ret_5d          0 non-null      float32\n",
      " 11  $ret_10d         0 non-null      float32\n",
      " 12  $ret_20d         0 non-null      float32\n",
      "dtypes: float32(12), float64(1)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>$ret_5d</th>\n",
       "      <th>$ret_10d</th>\n",
       "      <th>$ret_20d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrument</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AAPL</th>\n",
       "      <th>2025-10-28</th>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.029628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-29</th>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.037140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-30</th>\n",
       "      <td>-0.008211</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-31</th>\n",
       "      <td>-0.007989</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-03</th>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WMT</th>\n",
       "      <th>2025-11-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        $ret_5d  $ret_10d  $ret_20d\n",
       "instrument datetime                                \n",
       "AAPL       2025-10-28  0.002894  0.023234  0.029628\n",
       "           2025-10-29  0.008473  0.021894  0.037140\n",
       "           2025-10-30 -0.008211  0.004453       NaN\n",
       "           2025-10-31 -0.007989  0.007545       NaN\n",
       "           2025-11-03  0.005899 -0.001456       NaN\n",
       "...                         ...       ...       ...\n",
       "WMT        2025-11-20       NaN       NaN       NaN\n",
       "           2025-11-21       NaN       NaN       NaN\n",
       "           2025-11-24       NaN       NaN       NaN\n",
       "           2025-11-25       NaN       NaN       NaN\n",
       "           2025-11-26       NaN       NaN       NaN\n",
       "\n",
       "[858 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Attribution function\n",
    "def attribution(cohort, horizon=\"5\"):\n",
    "    col = f\"$ret_{horizon}d\"\n",
    "    rr = cohort[col].dropna().values.mean()\n",
    "    vol = cohort[col].dropna().values.std()\n",
    "    rr_ratio = rr / vol if vol > 0 else 0\n",
    "    return rr, vol, rr_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Trade list loop\n",
    "latest_date = features.index.get_level_values(\"datetime\").max()\n",
    "trade_dates = df_combined.index.get_level_values(\"datetime\").unique()\n",
    "\n",
    "if latest_date not in trade_dates:\n",
    "    trade_dates = trade_dates.append(pd.Index([latest_date]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP\n",
    "for date in trade_dates.sort_values():\n",
    "\n",
    "    if date not in df_combined.index.get_level_values(\"datetime\"):\n",
    "        continue\n",
    "\n",
    "    df_day = df_combined.xs(date, level=\"datetime\", drop_level=False)\n",
    "    if df_day.empty or df_day.shape[0] < 4:\n",
    "        continue\n",
    "\n",
    "    df_day_sorted = df_day.sort_values(\"score\", ascending=False)\n",
    "    top = df_day_sorted.head(2)\n",
    "    bottom = df_day_sorted.tail(2)\n",
    "\n",
    "    prints(f\"\\nüìÖ {date.date()} ‚Äî Trade List (Ensemble Model)\", \"trade_list_ensemble_log.txt\")\n",
    "    for horizon in [\"5\", \"10\", \"20\"]:\n",
    "        col = f\"$ret_{horizon}d\"\n",
    "        col_data = df_day[col]\n",
    "        if isinstance(col_data, pd.DataFrame):\n",
    "            col_data = col_data.iloc[:, 0]  # Take the first column explicitly\n",
    "        if col_data.isna().all():\n",
    "            continue\n",
    "        buy_rr, buy_vol, buy_rrr = attribution(top, horizon)\n",
    "        sell_rr, _, _ = attribution(bottom, horizon)\n",
    "        spread = buy_rr - sell_rr\n",
    "        prints(f\"  ‚è± {horizon}d ‚Üí Buy: {buy_rr:.2%}, Sell: {sell_rr:.2%}, Spread: {spread:.2%}, Vol: {buy_vol:.2%}, R/R: {buy_rrr:.2f}\", \"trade_list_ensemble_log.txt\")\n",
    "\n",
    "    #prints(f\"  Buys: {top.index.get_level_values('instrument').tolist()} ‚Äî Scores: {top['score'].tolist()}\", \"trade_list_ensemble_log.txt\")\n",
    "    #prints(f\"  Sells: {bottom.index.get_level_values('instrument').tolist()} ‚Äî Scores: {bottom['score'].tolist()}\", \"trade_list_ensemble_log.txt\")\n",
    "    def icon_score(score, is_buy=True):\n",
    "        if is_buy and score >= 0.2:\n",
    "            return f\"{score:.4f} ‚úÖ\"  # Strong buy\n",
    "        elif is_buy and score >= 0.15:\n",
    "            return f\"{score:.4f} ‚úîÔ∏è\"  # buy\n",
    "        elif not is_buy and score <= -0.2:\n",
    "            return f\"{score:.4f} ‚ùå\"  # Strong sell\n",
    "        else:\n",
    "            return score     # Neutral\n",
    "\n",
    "    # Print buys with ‚úÖ for strong buy\n",
    "    buy_instruments = top.index.get_level_values(\"instrument\").tolist()\n",
    "    buy_scores = [icon_score(s, is_buy=True) for s in top[\"score\"].tolist()]\n",
    "    prints(f\"  Buys: {buy_instruments} ‚Äî Scores: {buy_scores}\", \"trade_list_ensemble_log.txt\")\n",
    "\n",
    "    # Print sells with ‚ùå for strong sell\n",
    "    sell_instruments = bottom.index.get_level_values(\"instrument\").tolist()\n",
    "    sell_scores = [icon_score(s, is_buy=False) for s in bottom[\"score\"].tolist()]\n",
    "    prints(f\"  Sells: {sell_instruments} ‚Äî Scores: {sell_scores}\", \"trade_list_ensemble_log.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Average 5d return per score bucket:\n",
      "bucket\n",
      "0   -0.022294\n",
      "1   -0.008937\n",
      "2   -0.016779\n",
      "3   -0.015058\n",
      "4   -0.019760\n",
      "Name: label, dtype: float32\n",
      "‚úÖ Hit rate per bucket:\n",
      "bucket\n",
      "0    0.361702\n",
      "1    0.414286\n",
      "2    0.357143\n",
      "3    0.385714\n",
      "4    0.361702\n",
      "Name: label, dtype: float64\n",
      "\n",
      "üìä Core (>= 600 days) Attribution\n",
      "bucket\n",
      "0   -0.019079\n",
      "1   -0.008937\n",
      "2   -0.016825\n",
      "3   -0.014767\n",
      "4   -0.020121\n",
      "Name: label, dtype: float32\n",
      "bucket\n",
      "0    0.377778\n",
      "1    0.414286\n",
      "2    0.355072\n",
      "3    0.388489\n",
      "4    0.358779\n",
      "Name: label, dtype: float64\n",
      "\n",
      "üìä IPO (< 600 days) Attribution\n",
      "bucket\n",
      "0   -0.094621\n",
      "2   -0.013645\n",
      "3   -0.055447\n",
      "4   -0.015044\n",
      "Name: label, dtype: float32\n",
      "bucket\n",
      "0    0.0\n",
      "2    0.5\n",
      "3    0.0\n",
      "4    0.4\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#diagnostic:\n",
    "labels_renamed = labels.rename(columns={\n",
    "    \"$ret_5d\": \"ret_5d_label\",\n",
    "    \"$ret_10d\": \"ret_10d_label\",\n",
    "    \"$ret_20d\": \"ret_20d_label\",\n",
    "})\n",
    "\n",
    "df_combined = pd.concat([features, labels_renamed], axis=1)\n",
    "# Step 1: Reset index for easier slicing\n",
    "df_valid = df_combined.reset_index()\n",
    "\n",
    "# Step 2: Filter for dates with valid realized returns\n",
    "df_valid = df_valid[df_valid[\"$ret_5d\"].notna()]\n",
    "# Keep forward returns for evaluation diagnostics\n",
    "\n",
    "# Step 3: Rename columns for clarity (optional)\n",
    "df_valid = df_valid.rename(columns={\"score\": \"score\", \"$ret_5d\": \"label\"})\n",
    "\n",
    "# Step 4: Create score buckets\n",
    "df_valid[\"bucket\"] = pd.qcut(df_valid[\"score\"], q=5, labels=False)\n",
    "\n",
    "# Step 5: Attribution by bucket\n",
    "bucket_returns = df_valid.groupby(\"bucket\")[\"label\"].mean()\n",
    "prints(\"üìä Average 5d return per score bucket:\", \"trade_list_ensemble_log.txt\")\n",
    "prints(bucket_returns, \"trade_list_ensemble_log.txt\")\n",
    "hit_rate = df_valid.groupby(\"bucket\")[\"label\"].apply(lambda x: (x > 0).mean())\n",
    "prints(\"‚úÖ Hit rate per bucket:\", \"trade_list_ensemble_log.txt\")\n",
    "prints(hit_rate, \"trade_list_ensemble_log.txt\")\n",
    "\n",
    "\n",
    "IPO_CUTOFF = 600  # ~1 year of trading days\n",
    "\n",
    "df_valid[\"ipo_cohort\"] = (df_valid[\"$days_since_ipo\"] < IPO_CUTOFF).astype(int)\n",
    "\n",
    "# Attribution by cohort\n",
    "for cohort, name in [(0, \"Core (>= 600 days)\"), (1, \"IPO (< 600 days)\")]:\n",
    "    df_c = df_valid[df_valid[\"ipo_cohort\"] == cohort]\n",
    "    prints(f\"\\nüìä {name} Attribution\", \"trade_list_ensemble_log.txt\")\n",
    "    prints(df_c.groupby(\"bucket\")[\"label\"].mean(), \"trade_list_ensemble_log.txt\")\n",
    "    prints(df_c.groupby(\"bucket\")[\"label\"].apply(lambda x: (x > 0).mean()), \"trade_list_ensemble_log.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
